{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Viterbi HMM POS tagger\n",
    "author: Kailin Zheng<br>\n",
    "date: October 1 2019<br>\n",
    "class: HW3, NLP<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read Development file (WSJ_24.pos)\n",
    "\n",
    "#a list of sentence - each line has two lists: word and pos\n",
    "sentences = [] \n",
    "\n",
    "word = []\n",
    "pos = []\n",
    "\n",
    "\n",
    "f= open(\"WSJ_24.pos\",\"r+\")\n",
    "\n",
    "\n",
    "for line in f.readlines():\n",
    "    words = line.split()\n",
    "    \n",
    "    if (words == []):\n",
    "        sentences.append([word, pos])\n",
    "        word = []\n",
    "        pos = []\n",
    "    else:\n",
    "        word.append(words[0])\n",
    "        pos.append(words[1])\n",
    "f.close()  \n",
    "\n",
    "# f = open (\"WSJ_02-21.pos-chunk\",\"r+\")\n",
    "\n",
    "# for line in f.readlines():\n",
    "#     words = line.split()\n",
    "    \n",
    "#     if (words == []):\n",
    "#         sentences.append([word, pos])\n",
    "#         word = []\n",
    "#         pos = []\n",
    "#     else:\n",
    "#         word.append(words[0])\n",
    "#         pos.append(words[1])\n",
    "# f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentences[-1][1][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start state', 'DT', 'NN', 'POS', 'MD', 'VB', 'VBN', 'IN', 'JJ', 'NNS', ',', 'CC', '.', 'RBS', 'NNP', 'VBZ', 'TO', '$', 'CD', 'VBG', 'RB', 'VBD', 'PRP', 'PRP$', 'VBP', 'WRB', '``', 'EX', \"''\", ':', 'RBR', 'WP', 'JJR', 'WDT', 'RP', '#', 'PDT', 'UH', '-LRB-', '-RRB-', 'NNPS', 'JJS', 'SYM', 'FW', 'WP$', 'LS', 'final state']\n",
      "['The', 'economy', \"'s\", 'temperature', 'will', 'be', 'taken', 'from', 'several', 'vantage']\n"
     ]
    }
   ],
   "source": [
    "observed_words = []\n",
    "states = ['start state']\n",
    "Once = {}\n",
    "for i in range(len(sentences[:])):\n",
    "    for j in range(len(sentences[i][0])):\n",
    "        word = sentences[i][0][j]\n",
    "        tag = sentences[i][1][j]\n",
    "        if word in Once.keys():\n",
    "            del Once[word]\n",
    "        Once[word] = tag\n",
    "        \n",
    "        if (word not in observed_words):\n",
    "            observed_words.append(word)\n",
    "        if (tag not in states):\n",
    "            states.append(tag)\n",
    "states.append('final state')\n",
    "print(states)\n",
    "print(observed_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "OOV = pd.Series(0.0, index = states)\n",
    "for v in Once.keys():\n",
    "    OOV[Once[v]] += 1\n",
    "    \n",
    "OOV = OOV/len(Once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A = N тип N matrix such that a_i,j is the probability of the transition from q_i to q_j\n",
    "#B = lookup table such that bi(wt) is the probability that POS i is realized as word t\n",
    "#q0 = start state, q1...qN, qf = final state\n",
    "\n",
    "A = pd.DataFrame(0.0, index = states, columns = states)\n",
    "B = pd.DataFrame(0.0, index = observed_words, columns = states)\n",
    "\n",
    "\n",
    "for i in range(len(sentences[:])):\n",
    "    prev = 'start state'\n",
    "    for j in range(len(sentences[i][1])):\n",
    "        now = sentences[i][1][j]\n",
    "        A.loc[prev,now] += 1\n",
    "        prev = now\n",
    "        \n",
    "        B.loc[sentences[i][0][j], sentences[i][1][j]] += 1\n",
    "\n",
    "A = A.div(A.sum(axis=1), axis=0)\n",
    "B = B.div(B.sum(axis=1), axis=0)\n",
    "#B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Cover', ',', 'and', 'cook', 'for', '5', 'to', '6', 'hours', 'on', 'High', '.'], []]\n"
     ]
    }
   ],
   "source": [
    "#read test file (WSJ_23.pos)\n",
    "\n",
    "#a list of sentence - each line has two lists: word and pos\n",
    "S = [] \n",
    "\n",
    "word = []\n",
    "pos = []\n",
    "f= open(\"test_words.txt\",\"r+\")\n",
    "\n",
    "for line in f.readlines():\n",
    "    words = line.split()\n",
    "    \n",
    "    if (words == []):\n",
    "        S.append([word, pos])\n",
    "        word = []\n",
    "        pos = []\n",
    "    else:\n",
    "        word.append(words[0])\n",
    "    \n",
    "print(S[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_algo(A,B,S):\n",
    "    result = []\n",
    "    for i in range(len(S)):\n",
    "        if i % 50 == 0:\n",
    "            print(i)\n",
    "        \n",
    "        \n",
    "\n",
    "        viterbi = pd.DataFrame(0.0, index = states, columns = S[i][0])\n",
    "        viterbi.insert(0, column = '\\\\start', value = np.zeros(len(states)))\n",
    "        viterbi.insert(len(viterbi.columns), column = '\\\\end', value = 0.0)\n",
    "        viterbi.loc['start state', '\\\\start'] = 1\n",
    "        backpointer = pd.Series(-1, index = viterbi.columns)\n",
    "        \n",
    "        #initialize all states of the first word in viterbi: aka column[1]\n",
    "        for q in range(1, len(states)):\n",
    "            state = states[q]\n",
    "            first_word = S[i][0][0]\n",
    "            if (first_word not in observed_words):\n",
    "                viterbi.iloc[q,1] = A.iloc[0,q] * OOV[states[q]]\n",
    "            else:\n",
    "                viterbi.iloc[q,1] = A.iloc[0,q] * B.loc[first_word, state]\n",
    "            backpointer[1] = 0\n",
    "        #print(viterbi)\n",
    "        \n",
    "        #w in viterbi, starting 1 = w-1 in sentence, starting 0\n",
    "        for w in range(1, len(viterbi.columns)-1):\n",
    "            #print(i,',',w)\n",
    "            word = S[i][0][w-1]\n",
    "            score = 0\n",
    "            for q in range(len(states)): #state of prev word\n",
    "                if viterbi.iloc[q][w-1] == 0:\n",
    "                    continue\n",
    "                for p in range(len(states)): #state of curr word\n",
    "                    curr_state = states[p]\n",
    "                    if word not in observed_words:\n",
    "                        score = viterbi.iloc[q, w-1] * A.iloc[q,p] * OOV[states[q]]\n",
    "                    else:\n",
    "                        if B.loc[word, curr_state] == 0:\n",
    "                            continue\n",
    "                        score = viterbi.iloc[q, w-1] * A.iloc[q,p] * B.loc[word, curr_state]\n",
    "                    if score > viterbi.iloc[p,w]:\n",
    "                        viterbi.iloc[p,w] = score\n",
    "                        backpointer[w] = q\n",
    "        \n",
    "\n",
    "        max_index = -1\n",
    "        for q in range(len(states)):\n",
    "            if viterbi.iloc[q,-2] > viterbi.iloc[-1,-1]:\n",
    "                max_index = q\n",
    "                viterbi.iloc[-1,-1] = viterbi.iloc[q,-2]\n",
    "                backpointer[-1] = q\n",
    "                \n",
    "\n",
    "        #print(viterbi)\n",
    "        #print(backpointer)\n",
    "        result.append(backpointer)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n"
     ]
    }
   ],
   "source": [
    "backpointers = viterbi_algo(A,B,S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = open(\"test.pos\",\"w+\")\n",
    "for i in range(len(S)):\n",
    "\n",
    "    b = backpointers[i]\n",
    "    for w in range(len(S[i][0])):\n",
    "        result.write(S[i][0][w]+'\\t'+states[b[w+2]])\n",
    "        result.write('\\n')\n",
    "    result.write('\\n')\n",
    "result.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = len(open(\"test.pos\").readlines(  ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6587"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
